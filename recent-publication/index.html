<!DOCTYPE html><html lang="en-us" >

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Abhay Potharaju">

  
  
  
    
  
  <meta name="description" content="Recent Publications">

  
  <link rel="alternate" hreflang="en-us" href="https://goodwillcomputinglab.github.io/recent-publication/">

  


  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      
        
      

      
    
      

      
      

      
    

  

  
  
  
    
      
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
    
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  




  


  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="https://goodwillcomputinglab.github.io/recent-publication/">

  
  
  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Goodwill Computing Lab">
  <meta property="og:url" content="https://goodwillcomputinglab.github.io/recent-publication/">
  <meta property="og:title" content="Recent Publications | Goodwill Computing Lab">
  <meta property="og:description" content="Recent Publications"><meta property="og:image" content="https://goodwillcomputinglab.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png">
  <meta property="twitter:image" content="https://goodwillcomputinglab.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2019-01-01T00:00:00&#43;00:00">
    
    <meta property="article:modified_time" content="2019-01-01T00:00:00&#43;00:00">
  

  



  


  


  





  <title>Recent Publications | Goodwill Computing Lab</title>

</head>
<body id="top" data-spy="scroll" data-offset="70" data-target="#navbar-main" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  









<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container-fluid">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Goodwill Computing Lab</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Goodwill Computing Lab</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link  active" href="/" data-target="[]"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/people"><span>Team</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/research/"><span>Research</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link  active" href="/recent-publication/" data-target="[]"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/outreach"><span>Educational Outreach</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/artifacts"><span>Open-Source Artifacts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/news/"><span>News</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/contact"><span>Join Us</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link js-theme-selector" data-toggle="dropdown" aria-haspopup="true">
          <i class="fas fa-palette" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      

    </ul>

  </div>
</nav>


  
<span class="js-widget-page d-none"></span>





  
  
  
  




  
  
  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="publications" class="home-section wg-recent-pubs   "  >
    <div class="container">
      












































<div class="header">
    <h1>Selected Recent Publications</h1>
    
  </div>
  <div class="row">
  <div class="col-lg-12">
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [SC 2020]
          
        </span>
        <a href="https://doi.org/10.1109/TPDS.2018.2865471" class="article-title" 
          style="color:inherit; font-weight: normal;">Experimental Evaluation of NISQ Quantum Computers: Error Measurement, Characterization, and Implications (Best Paper Finalist, Best Student Paper Finalist)</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-journalstpds-temp\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1109/TPDS.2018.2865471" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-journalstpds-temp\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-journalstpds-temp/-abstract" style="display: none;">
            <p class="abstract abstract-text">The need for novel data analysis is urgent in the face of a data deluge from modern applications. Traditional approaches to data analysis incur significant data movement costs, moving data back and forth between the storage system and the processor. Emerging Active Flash devices enable processing on the flash, where the data already resides. An array of such Active Flash devices allows us to revisit how analysis workflows interact with storage systems. By seamlessly blending together the flash storage and data analysis, we create an analysis workflow-aware storage system, AnalyzeThis. Our guiding principle is that analysis-awareness be deeply ingrained in each and every layer of the storage, elevating data analyses as first-class citizens, and transforming AnalyzeThis into a potent analytics-aware appliance. To evaluate the AnalyzeThis system, we have adopted both emulation and simulation approaches. In particular, we have evaluated AnalyzeThis by implementing the AnalyzeThis storage system on top of the Active Flash Array's emulation platform. We have also implemented an event-driven AnalyzeThis simulator, called AnalyzeThisSim, which allows us to address the limitations of the emulation platform, e.g., performance impact of using multi-core SSDs. The results from our emulation and simulation platforms indicate that AnalyzeThis is a viable approach for expediting workflow execution and minimizing data movement.</p>
          </div>
          
          
          <div id="/publication/dblp-journalstpds-temp/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-journalstpds-temp/-cite" class="tex hljs" data-filename="/publication/dblp-journalstpds-temp/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [SC 2020]
          
        </span>
        <a href="https://doi.org/10.1109/TPDS.2018.2865471" class="article-title" 
          style="color:inherit; font-weight: normal;">Job Characteristics on Large-Scale Systems: Long-Term Analysis, Quantification and Implications</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/temp3\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1109/TPDS.2018.2865471" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/temp3\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/temp3/-abstract" style="display: none;">
            <p class="abstract abstract-text">The need for novel data analysis is urgent in the face of a data deluge from modern applications. Traditional approaches to data analysis incur significant data movement costs, moving data back and forth between the storage system and the processor. Emerging Active Flash devices enable processing on the flash, where the data already resides. An array of such Active Flash devices allows us to revisit how analysis workflows interact with storage systems. By seamlessly blending together the flash storage and data analysis, we create an analysis workflow-aware storage system, AnalyzeThis. Our guiding principle is that analysis-awareness be deeply ingrained in each and every layer of the storage, elevating data analyses as first-class citizens, and transforming AnalyzeThis into a potent analytics-aware appliance. To evaluate the AnalyzeThis system, we have adopted both emulation and simulation approaches. In particular, we have evaluated AnalyzeThis by implementing the AnalyzeThis storage system on top of the Active Flash Array's emulation platform. We have also implemented an event-driven AnalyzeThis simulator, called AnalyzeThisSim, which allows us to address the limitations of the emulation platform, e.g., performance impact of using multi-core SSDs. The results from our emulation and simulation platforms indicate that AnalyzeThis is a viable approach for expediting workflow execution and minimizing data movement.</p>
          </div>
          
          
          <div id="/publication/temp3/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/temp3/-cite" class="tex hljs" data-filename="/publication/temp3/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            [USENIX ATC 2020]
          
        </span>
        <a href="https://doi.org/10.1109/TPDS.2018.2865471" class="article-title" 
          style="color:inherit; font-weight: normal;">UREQA: Leveraging Operation-Aware Error Rates for Effective Quantum Circuit Mapping on NISQ-Era Quantum Computers</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/temp5\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1109/TPDS.2018.2865471" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/temp5\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/temp5/-abstract" style="display: none;">
            <p class="abstract abstract-text">The need for novel data analysis is urgent in the face of a data deluge from modern applications. Traditional approaches to data analysis incur significant data movement costs, moving data back and forth between the storage system and the processor. Emerging Active Flash devices enable processing on the flash, where the data already resides. An array of such Active Flash devices allows us to revisit how analysis workflows interact with storage systems. By seamlessly blending together the flash storage and data analysis, we create an analysis workflow-aware storage system, AnalyzeThis. Our guiding principle is that analysis-awareness be deeply ingrained in each and every layer of the storage, elevating data analyses as first-class citizens, and transforming AnalyzeThis into a potent analytics-aware appliance. To evaluate the AnalyzeThis system, we have adopted both emulation and simulation approaches. In particular, we have evaluated AnalyzeThis by implementing the AnalyzeThis storage system on top of the Active Flash Array's emulation platform. We have also implemented an event-driven AnalyzeThis simulator, called AnalyzeThisSim, which allows us to address the limitations of the emulation platform, e.g., performance impact of using multi-core SSDs. The results from our emulation and simulation platforms indicate that AnalyzeThis is a viable approach for expediting workflow execution and minimizing data movement.</p>
          </div>
          
          
          <div id="/publication/temp5/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/temp5/-cite" class="tex hljs" data-filename="/publication/temp5/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [SC 2020]
          
        </span>
        <a href="https://doi.org/10.1109/TPDS.2018.2865471" class="article-title" 
          style="color:inherit; font-weight: normal;">VERITAS: Accurately Estimating the Correct Output on Noisy Intermediate-Scale Quantum Computers</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/temp2\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1109/TPDS.2018.2865471" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/temp2\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/temp2/-abstract" style="display: none;">
            <p class="abstract abstract-text">The need for novel data analysis is urgent in the face of a data deluge from modern applications. Traditional approaches to data analysis incur significant data movement costs, moving data back and forth between the storage system and the processor. Emerging Active Flash devices enable processing on the flash, where the data already resides. An array of such Active Flash devices allows us to revisit how analysis workflows interact with storage systems. By seamlessly blending together the flash storage and data analysis, we create an analysis workflow-aware storage system, AnalyzeThis. Our guiding principle is that analysis-awareness be deeply ingrained in each and every layer of the storage, elevating data analyses as first-class citizens, and transforming AnalyzeThis into a potent analytics-aware appliance. To evaluate the AnalyzeThis system, we have adopted both emulation and simulation approaches. In particular, we have evaluated AnalyzeThis by implementing the AnalyzeThis storage system on top of the Active Flash Array's emulation platform. We have also implemented an event-driven AnalyzeThis simulator, called AnalyzeThisSim, which allows us to address the limitations of the emulation platform, e.g., performance impact of using multi-core SSDs. The results from our emulation and simulation platforms indicate that AnalyzeThis is a viable approach for expediting workflow execution and minimizing data movement.</p>
          </div>
          
          
          <div id="/publication/temp2/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/temp2/-cite" class="tex hljs" data-filename="/publication/temp2/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [ICCAD 2020]
          
        </span>
        <a href="https://doi.org/10.1109/TPDS.2018.2865471" class="article-title" 
          style="color:inherit; font-weight: normal;">DISQ: A Novel Quantum Output State Classification Method on IBM Quantum Computers using OpenPulse (Best Paper Finalist)</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/temp4\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1109/TPDS.2018.2865471" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/temp4\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/temp4/-abstract" style="display: none;">
            <p class="abstract abstract-text">The need for novel data analysis is urgent in the face of a data deluge from modern applications. Traditional approaches to data analysis incur significant data movement costs, moving data back and forth between the storage system and the processor. Emerging Active Flash devices enable processing on the flash, where the data already resides. An array of such Active Flash devices allows us to revisit how analysis workflows interact with storage systems. By seamlessly blending together the flash storage and data analysis, we create an analysis workflow-aware storage system, AnalyzeThis. Our guiding principle is that analysis-awareness be deeply ingrained in each and every layer of the storage, elevating data analyses as first-class citizens, and transforming AnalyzeThis into a potent analytics-aware appliance. To evaluate the AnalyzeThis system, we have adopted both emulation and simulation approaches. In particular, we have evaluated AnalyzeThis by implementing the AnalyzeThis storage system on top of the Active Flash Array's emulation platform. We have also implemented an event-driven AnalyzeThis simulator, called AnalyzeThisSim, which allows us to address the limitations of the emulation platform, e.g., performance impact of using multi-core SSDs. The results from our emulation and simulation platforms indicate that AnalyzeThis is a viable approach for expediting workflow execution and minimizing data movement.</p>
          </div>
          
          
          <div id="/publication/temp4/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/temp4/-cite" class="tex hljs" data-filename="/publication/temp4/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [IPDPS 2020]
          
        </span>
        <a href="https://doi.org/10.1109/IPDPS47924.2020.00087" class="article-title" 
          style="color:inherit; font-weight: normal;">What does Power Consumption Behavior of HPC Jobs Reveal? : Demystifying, Quantifying, and Predicting Power Consumption Characteristics</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-confipps-patel-wehzt-20\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1109/IPDPS47924.2020.00087" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-confipps-patel-wehzt-20\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-confipps-patel-wehzt-20/-abstract" style="display: none;">
            <p class="abstract abstract-text">As we approach exascale computing, large-scale HPC systems are becoming increasingly power-constrained, requiring them to run HPC workloads in an energy-efficient manner. The first step toward achieving this goal is to better understand, analyze, and quantify the power consumption characteristics of HPC jobs. However, there is a lack of understanding of the power consumption characteristics of HPC jobs which run on production HPC systems. Such characterization is required to guide the design of the next generation of power-aware resource management. To the best of our knowledge, we are the first study to open-source the data and analysis of power-consumption characteristics of HPC jobs and users from two medium-scale production HPC clusters.</p>
          </div>
          
          
          <div id="/publication/dblp-confipps-patel-wehzt-20/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-confipps-patel-wehzt-20/-cite" class="tex hljs" data-filename="/publication/dblp-confipps-patel-wehzt-20/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [HPCA 2020]
          
        </span>
        <a href="https://doi.org/10.1109/HPCA47549.2020.00025" class="article-title" 
          style="color:inherit; font-weight: normal;">CLITE: Efficient and QoS-Aware Co-Location of Multiple Latency-Critical Jobs for Warehouse Scale Computers</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-confhpca-patel-t-20\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1109/HPCA47549.2020.00025" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-confhpca-patel-t-20\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-confhpca-patel-t-20/-abstract" style="display: none;">
            <p class="abstract abstract-text">Large-scale data centers run latency-critical jobs with quality-of-service (QoS) requirements, and throughput-oriented background jobs, which need to achieve high perfor-mance. Previous works have proposed methods which cannot co-locate multiple latency-critical jobs with multiple back-grounds jobs while: (1) meeting the QoS requirements of all latency-critical jobs, and (2) maximizing the performance of the background jobs. This paper proposes CLITE, a Bayesian Optimization-based, multi-resource partitioning technique which achieves these goals.</p>
          </div>
          
          
          <div id="/publication/dblp-confhpca-patel-t-20/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-confhpca-patel-t-20/-cite" class="tex hljs" data-filename="/publication/dblp-confhpca-patel-t-20/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [FAST 2020]
          
        </span>
        <a href="https://www.usenix.org/conference/fast20/presentation/patel-gift" class="article-title" 
          style="color:inherit; font-weight: normal;">GIFT: A Coupon Based Throttle-and-Reward Mechanism for Fair and Efficient I/O Bandwidth Management on Parallel Storage Systems</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-conffast-patel-0-t-20\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://www.usenix.org/conference/fast20/presentation/patel-gift" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-conffast-patel-0-t-20\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-conffast-patel-0-t-20/-abstract" style="display: none;">
            <p class="abstract abstract-text">Large-scale parallel applications are highly data-intensive and perform terabytes of I/O routinely. Unfortunately, on a large-scale system where multiple applications run concurrently, I/O contention negatively affects system efficiency and causes unfair bandwidth allocation among applications. To address these challenges, this paper introduces GIFT, a principled dynamic approach to achieve fairness among competing applications and improve system efficiency.</p>
          </div>
          
          
          <div id="/publication/dblp-conffast-patel-0-t-20/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-conffast-patel-0-t-20/-cite" class="tex hljs" data-filename="/publication/dblp-conffast-patel-0-t-20/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [FAST 2020]
          
        </span>
        <a href="https://www.usenix.org/conference/fast20/presentation/patel-hpc-systems" class="article-title" 
          style="color:inherit; font-weight: normal;">Uncovering Access, Reuse, and Sharing Characteristics of I/O-Intensive Files on Large-Scale Production HPC Systems</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-conffast-patel-blwcrt-20\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://www.usenix.org/conference/fast20/presentation/patel-hpc-systems" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-conffast-patel-blwcrt-20\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-conffast-patel-blwcrt-20/-abstract" style="display: none;">
            <p class="abstract abstract-text">Large-scale high-performance computing (HPC) applications running on supercomputers produce large amounts of data routinely and store it in files on multi-PB shared parallel storage systems. Unfortunately, storage community has a limited understanding of the access and reuse patterns of these files. This paper investigates the access and reuse patterns of I/O- intensive files on a production-scale supercomputer.</p>
          </div>
          
          
          <div id="/publication/dblp-conffast-patel-blwcrt-20/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-conffast-patel-blwcrt-20/-cite" class="tex hljs" data-filename="/publication/dblp-conffast-patel-blwcrt-20/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [FAST 2020]
          
        </span>
        <a href="https://www.usenix.org/conference/fast20/presentation/lu" class="article-title" 
          style="color:inherit; font-weight: normal;">Making Disk Failure Predictions SMARTer!</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-conffast-lu-lpyts-20\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://www.usenix.org/conference/fast20/presentation/lu" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-conffast-lu-lpyts-20\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-conffast-lu-lpyts-20/-abstract" style="display: none;">
            <p class="abstract abstract-text">Disk drives are one of the most commonly replaced hardware components and continue to pose challenges for accurate failure prediction. In this work, we present analysis and findings from one of the largest disk failure prediction studies covering a total of 380,000 hard drives over a period of two months across 64 sites of a large leading data center operator. Our proposed machine learning based models predict disk failures with 0.95 F-measure and 0.95 Matthews correlation coefficient (MCC) for 10-days prediction horizon on average.</p>
          </div>
          
          
          <div id="/publication/dblp-conffast-lu-lpyts-20/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-conffast-lu-lpyts-20/-cite" class="tex hljs" data-filename="/publication/dblp-conffast-lu-lpyts-20/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [ICAC 2019]
          
        </span>
        <a href="https://doi.org/10.1109/ICAC.2019.00027" class="article-title" 
          style="color:inherit; font-weight: normal;">Characterizing Disk Health Degradation and Proactively Protecting Against Disk Failures for Reliable Storage Systems</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-conficac-huang-lfstc-19\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1109/ICAC.2019.00027" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-conficac-huang-lfstc-19\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-conficac-huang-lfstc-19/-abstract" style="display: none;">
            <p class="abstract abstract-text">The booming of cloud computing, online services and big data applications have resulted in dramatic expansion of storage systems. Meanwhile, disk drives are reported to be the most commonly replaced hardware component. Disk failures cause service downtime and even data loss, costing enterprises multi-trillion dollars per year. Existing disk failure management approaches are mostly reactive and incur high overheads. To overcome these problems, in this paper, we present a proactive, cost-effective solution to managing large-scale production storage systems. We aim to uncover the entire process in which disk's health deteriorates and forecast when disk drives will fail in the future. Due to a common lack of diagnostic information of disk failures, we rely on the Self-Monitoring, Analysis and Reporting Technology (SMART) data and explore statistical analysis techniques to identify the start of disk degradation. We then model the disk degradation processes as functions of SMART attributes, which eliminates the dependency on time and thus I/O workload. Experimental results from over 23,000 enterprise-class disk drives in a production data center show that our derived models can accurately quantify the degradation of disk health, which enables us to proactively protect data against disk failures. We also investigate several types of disk failures and propose remediation mechanisms to prolong disk lifetime.</p>
          </div>
          
          
          <div id="/publication/dblp-conficac-huang-lfstc-19/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-conficac-huang-lfstc-19/-cite" class="tex hljs" data-filename="/publication/dblp-conficac-huang-lfstc-19/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [DATE 2019]
          
        </span>
        <a href="https://doi.org/10.23919/DATE.2019.8714781" class="article-title" 
          style="color:inherit; font-weight: normal;">PCFI: Program Counter Guided Fault Injection for Accelerating GPU Reliability Assessment</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-confdate-previlon-ktk-19\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.23919/DATE.2019.8714781" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-confdate-previlon-ktk-19\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-confdate-previlon-ktk-19/-abstract" style="display: none;">
            <p class="abstract abstract-text">Reliability has become a first-class design objective for GPU devices due to increasing soft-error rate. To assess the reliability of GPU programs, researchers rely on software fault-injection methods. Unfortunately, software fault-injection process is prohibitively expensive, requiring multiple days to complete a statistically sound fault-injection campaign. Therefore, to address this challenge, this paper proposes a novel fault-injection method, PCFI, that reduces the number of fault injections by exploiting the predictability in fault-injection outcome based on the program counter of the soft-error affected instruction. Evaluation on a variety of GPU programs covering a wide range of application domains shows that PCFI reduces the time to complete fault-injection campaigns by 22% on average, without sacrificing accuracy.</p>
          </div>
          
          
          <div id="/publication/dblp-confdate-previlon-ktk-19/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-confdate-previlon-ktk-19/-cite" class="tex hljs" data-filename="/publication/dblp-confdate-previlon-ktk-19/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [HPDC 2019]
          
        </span>
        <a href="https://doi.org/10.1145/3307681.3326607" class="article-title" 
          style="color:inherit; font-weight: normal;">PERQ: Fair and Efficient Power Management of Power-Constrained Large-Scale Computing Systems</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-confhpdc-patel-t-19\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1145/3307681.3326607" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-confhpdc-patel-t-19\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-confhpdc-patel-t-19/-abstract" style="display: none;">
            <p class="abstract abstract-text">Large-scale computing systems are becoming increasingly more power-constrained, but these systems employ hardware over- provisioning to achieve higher system throughput because applications often do not consume the peak power capacity of nodes. Unfortunately, focusing on system throughput alone can lead to severe unfairness among multiple concurrently-running applications. This paper introduces PERQ, a new feedback-based principled approach to improve system throughput while achieving fairness among concurrent applications.</p>
          </div>
          
          
          <div id="/publication/dblp-confhpdc-patel-t-19/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-confhpdc-patel-t-19/-cite" class="tex hljs" data-filename="/publication/dblp-confhpdc-patel-t-19/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [SC 2019]
          
        </span>
        <a href="https://doi.org/10.1145/3295500.3356183" class="article-title" 
          style="color:inherit; font-weight: normal;">Revisiting I/O behavior in large-scale storage systems: the expected and the unexpected</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-confsc-patel-blt-19\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1145/3295500.3356183" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-confsc-patel-blt-19\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-confsc-patel-blt-19/-abstract" style="display: none;">
            <p class="abstract abstract-text">Large-scale applications typically spend a large fraction of their execution time performing I/O to a parallel storage system. However, with rapid progress in compute and storage system stack of large-scale systems, it is critical to investigate and update our understanding of the I/O behavior of large-scale applications. Toward that end, in this work, we monitor, collect and analyze a year worth of storage system data from a large-scale production parallel storage system. We perform temporal, spatial and correlative analysis of the system and uncover surprising patterns which defy existing assumptions and have important implications for future systems.</p>
          </div>
          
          
          <div id="/publication/dblp-confsc-patel-blt-19/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-confsc-patel-blt-19/-cite" class="tex hljs" data-filename="/publication/dblp-confsc-patel-blt-19/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [DAC 2019]
          
        </span>
        <a href="https://doi.org/10.1145/3316781.3317931" class="article-title" 
          style="color:inherit; font-weight: normal;">What does Vibration do to Your SSD?</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-confdac-bhimani-pmt-19\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1145/3316781.3317931" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-confdac-bhimani-pmt-19\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-confdac-bhimani-pmt-19/-abstract" style="display: none;">
            <p class="abstract abstract-text">Vibration generated in modern computing environments such as autonomous vehicles, edge computing infrastructure, and data center systems is an increasing concern. In this paper, we systematically measure, quantify and characterize the impact of vibration on the performance of SSD devices. Our experiments and analysis uncover that exposure to both short-term and long-term vibration, even within the vendor-specified limits, can significantly affect SSD I/O performance and reliability.</p>
          </div>
          
          
          <div id="/publication/dblp-confdac-bhimani-pmt-19/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-confdac-bhimani-pmt-19/-cite" class="tex hljs" data-filename="/publication/dblp-confdac-bhimani-pmt-19/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [DSN 2018]
          
        </span>
        <a href="https://doi.org/10.1109/DSN.2018.00023" class="article-title" 
          style="color:inherit; font-weight: normal;">Understanding and Analyzing Interconnect Errors and Network Congestion on a Large Scale HPC System</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-confdsn-kumar-gpwsfet-18\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1109/DSN.2018.00023" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-confdsn-kumar-gpwsfet-18\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-confdsn-kumar-gpwsfet-18/-abstract" style="display: none;">
            <p class="abstract abstract-text">Today's High Performance Computing (HPC) systems are capable of delivering performance in the order of petaflops due to the fast computing devices, network interconnect, and back-end storage systems. In particular, interconnect resilience and congestion resolution methods have a major impact on the overall interconnect and application performance. This is especially true for scientific applications running multiple processes on different compute nodes as they rely on fast network messages to communicate and synchronize frequently. Unfortunately, the HPC community lacks state-of-practice experience reports that detail how different interconnect errors and congestion events occur on large-scale HPC systems. Therefore, in this paper, we process and analyze interconnect data of the Titan supercomputer to develop a thorough understanding of interconnects faults, errors and congestion events. We also study the interaction between interconnect, errors, network congestion and application characteristics.</p>
          </div>
          
          
          <div id="/publication/dblp-confdsn-kumar-gpwsfet-18/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-confdsn-kumar-gpwsfet-18/-cite" class="tex hljs" data-filename="/publication/dblp-confdsn-kumar-gpwsfet-18/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [BD 2018]
          
        </span>
        <a href="https://doi.org/10.1109/BigData.2018.8622643" class="article-title" 
          style="color:inherit; font-weight: normal;">Reliability Characterization of Solid State Drives in a Scalable Production Datacenter</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-confbigdataconf-liang-qhhfstcsm-18\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1109/BigData.2018.8622643" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-confbigdataconf-liang-qhhfstcsm-18\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-confbigdataconf-liang-qhhfstcsm-18/-abstract" style="display: none;">
            <p class="abstract abstract-text">In recent years, NAND flash-based solid state drives (SSD) have been widely used in datacenters due to their better performance compared with the traditional hard disk drives. However, little is known about the reliability characteristics of SSDs in production systems. Existing works study the statistical distributions of SSD failures in the field. However, they do not go deep into SSD drives and investigate the unique error types and health dynamics that distinguish SSDs from hard disk drives. In this paper, we explore the SSD-specific SMART (Self-Monitoring, Analysis, and Reporting Technology) attributes to conduct an in-depth analysis of SSD reliability in a production environment. Data is collected from a scalable production system having several physical locations. Our dataset contains over a million records with more than twenty attributes. We leverage machine learning technologies, specifically data clustering and correlation analysis methods, to discover groups of SSDs which have different health status and relations among SSD-specific SMART attributes. Our results show that 1) Media wear affects the reliability of SSDs more than any other factors, and 2) SSDs transit from one health group to another which infers the reliability degradation of those drives. To the best of our knowledge, this is the first study that investigates SSD-specific SMART data to characterize SSD reliability in a production environment.</p>
          </div>
          
          
          <div id="/publication/dblp-confbigdataconf-liang-qhhfstcsm-18/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-confbigdataconf-liang-qhhfstcsm-18/-cite" class="tex hljs" data-filename="/publication/dblp-confbigdataconf-liang-qhhfstcsm-18/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [ACM 2018]
          
        </span>
        <a href="https://doi.org/10.1109/ASONAM.2018.8508541" class="article-title" 
          style="color:inherit; font-weight: normal;">Resilience and the Coevolution of Interdependent Multiplex Networks</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-confasunam-ganguly-mst-18\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1109/ASONAM.2018.8508541" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-confasunam-ganguly-mst-18\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-confasunam-ganguly-mst-18/-abstract" style="display: none;">
            <p class="abstract abstract-text">We propose a new model for the study of resilience of coevolving multiplex scale-free networks. Our network model, called preferential interdependent networks, is a novel continuum over scale-free networks parameterized by their correlation p, 0 ≤ p ≤1. Our failure and recovery model ties the propensity of a node, both to fail and to assist in recovery, to its importance. We show, analytically, that our network model can achieve any γ, 2 ≤ γ ≤ 3 for the exponent of the power law of the degree distribution; this is superior to existing multiplex models and allows us better fidelity in representing real-world networks. Our failure and recovery model is also a departure from the much studied cascading error model based on the giant component; it allows for surviving important nodes to send assistance to the damaged nodes to enable their recovery. This better reflects the reality of recovery in man-made networks such as social networks and infrastructure networks. Our main finding, based on simulations, is that resilient preferential interdependent networks are those in which the layers are neither completely correlated (p = 1) nor completely uncorrelated (p= 0) but instead semi-correlated (p ≈ 0.1 - 0.3). This finding is consistent with the real-world experience where complex man-made networks typically bounce back quickly from stress. In an attempt to explain our intriguing empirical discovery we present an argument for why semi-correlated multiplex networks can be the most resilient. Our argument can be seen as an explanation of plausibility or as an incomplete mathematical proof subject to certain technical conjectures that we make explicit.</p>
          </div>
          
          
          <div id="/publication/dblp-confasunam-ganguly-mst-18/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-confasunam-ganguly-mst-18/-cite" class="tex hljs" data-filename="/publication/dblp-confasunam-ganguly-mst-18/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [DSN 2018]
          
        </span>
        <a href="https://doi.org/10.1109/DSN.2018.00021" class="article-title" 
          style="color:inherit; font-weight: normal;">Shiraz: Exploiting System Reliability and Application Resilience Characteristics to Improve Large Scale System Throughput</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-confdsn-garg-pct-18\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1109/DSN.2018.00021" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-confdsn-garg-pct-18\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-confdsn-garg-pct-18/-abstract" style="display: none;">
            <p class="abstract abstract-text">Large-scale applications rely on resilience mechanisms such as checkpoint-restart to make forward progress in the presence of failures. Unfortunately, this incurs huge I/O overhead and impedes productivity. To mitigate this challenge, this paper introduces a new technique, Shiraz, which demonstrates how to exploit differences in the checkpointing overhead among applications and knowledge of temporal characteristics of failures to improve both the overall system throughput and performance of individual applications.</p>
          </div>
          
          
          <div id="/publication/dblp-confdsn-garg-pct-18/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-confdsn-garg-pct-18/-cite" class="tex hljs" data-filename="/publication/dblp-confdsn-garg-pct-18/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [DSN 2018]
          
        </span>
        <a href="https://doi.org/10.1109/DSN.2018.00022" class="article-title" 
          style="color:inherit; font-weight: normal;">Machine Learning Models for GPU Error Prediction in a Large Scale HPC System</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-confdsn-nie-xgpest-18\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1109/DSN.2018.00022" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-confdsn-nie-xgpest-18\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-confdsn-nie-xgpest-18/-abstract" style="display: none;">
            <p class="abstract abstract-text">GPUs are widely deployed on large-scale HPC systems to provide powerful computational capability for scientific applications from various domains. As those applications are normally long-running, investigating the characteristics of GPU errors becomes imperative for reliability. In this paper, we first study the system conditions that trigger GPU errors using six-month trace data collected from a large-scale, operational HPC system. Then, we use machine learning to predict the occurrence of GPU errors, by taking advantage of temporal and spatial dependencies of the trace data. The resulting machine learning prediction framework is robust and accurate under different workloads.</p>
          </div>
          
          
          <div id="/publication/dblp-confdsn-nie-xgpest-18/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-confdsn-nie-xgpest-18/-cite" class="tex hljs" data-filename="/publication/dblp-confdsn-nie-xgpest-18/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [MASCOTS 2017]
          
        </span>
        <a href="https://doi.org/10.1109/MASCOTS.2017.12" class="article-title" 
          style="color:inherit; font-weight: normal;">Characterizing Temperature, Power, and Soft-Error Behaviors in Data Center Systems: Insights, Challenges, and Opportunities</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-confmascots-nie-xgest-17\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1109/MASCOTS.2017.12" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-confmascots-nie-xgest-17\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-confmascots-nie-xgest-17/-abstract" style="display: none;">
            <p class="abstract abstract-text">GPUs have become part of the mainstream high performance computing facilities that increasingly require more computational power to simulate physical phenomena quickly and accurately. However, GPU nodes also consume significantly more power than traditional CPU nodes, and high power consumption introduces new system operation challenges, including increased temperature, power/cooling cost, and lower system reliability. This paper explores how power consumption and temperature characteristics affect reliability, provides insights into what are the implications of such understanding, and how to exploit these insights toward predicting GPU errors using neural networks.</p>
          </div>
          
          
          <div id="/publication/dblp-confmascots-nie-xgest-17/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-confmascots-nie-xgest-17/-cite" class="tex hljs" data-filename="/publication/dblp-confmascots-nie-xgest-17/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [CLUSTER 2017]
          
        </span>
        <a href="https://doi.org/10.1109/CLUSTER.2017.22" class="article-title" 
          style="color:inherit; font-weight: normal;">Effective Running of End-to-End HPC Workflows on Emerging Heterogeneous Architectures</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-confcluster-tang-tgvh-17\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1109/CLUSTER.2017.22" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-confcluster-tang-tgvh-17\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-confcluster-tang-tgvh-17/-abstract" style="display: none;">
            <p class="abstract abstract-text">In high-performance computing (HPC), end-to-end workflows are typically utilized to gain insights from scientific simulations. An end-to-end workflow consists of scientific simulation and data analysis, and can be executed in-situ, in-transit, and offline. Existing studies on end-to-end workflows have largely focused on the high-performance execution approaches. However, the emerging heterogeneous architectures and energy concerns lead to the rethinking of workflow execution approaches. As a guide to the rethinking, this paper evaluates how to run end-to-end HPC workflows efficiently in terms of performance, energy, and error resilience. The evaluation covers emerging heterogeneous processor architectures, processor power capping techniques, and heterogeneous-reliability memory.</p>
          </div>
          
          
          <div id="/publication/dblp-confcluster-tang-tgvh-17/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-confcluster-tang-tgvh-17/-cite" class="tex hljs" data-filename="/publication/dblp-confcluster-tang-tgvh-17/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [SC 2017]
          
        </span>
        <a href="https://doi.org/10.1145/3126908.3126937" class="article-title" 
          style="color:inherit; font-weight: normal;">Failures in large scale systems: long-term measurement, analysis, and implications</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-confsc-gupta-pet-17\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1145/3126908.3126937" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-confsc-gupta-pet-17\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-confsc-gupta-pet-17/-abstract" style="display: none;">
            <p class="abstract abstract-text">Resilience is one of the key challenges in maintaining high efficiency of future extreme scale supercomputers. Researchers and system practitioners rely on field-data studies to understand reliability characteristics and plan for future HPC systems. In this work, we compare and contrast the reliability characteristics of multiple large-scale HPC production systems. Our study covers more than one billion compute node hours across five different systems over a period of 8 years. We confirm previous findings which continue to be valid, discover new findings, and discuss their implications.</p>
          </div>
          
          
          <div id="/publication/dblp-confsc-gupta-pet-17/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-confsc-gupta-pet-17/-cite" class="tex hljs" data-filename="/publication/dblp-confsc-gupta-pet-17/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [SC 2017]
          
        </span>
        <a href="https://doi.org/10.1145/3126908.3126946" class="article-title" 
          style="color:inherit; font-weight: normal;">GUIDE: a scalable information directory service to collect, federate, and analyze logs for operational insights into a leadership HPC facility</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-confsc-vazhkudai-mtzwog-17\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1145/3126908.3126946" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-confsc-vazhkudai-mtzwog-17\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-confsc-vazhkudai-mtzwog-17/-abstract" style="display: none;">
            <p class="abstract abstract-text">In this paper, we describe the GUIDE framework used to collect, federate, and analyze log data from the Oak Ridge Leadership Computing Facility (OLCF), and how we use that data to derive insights into facility operations. We collect system logs and extract monitoring data at every level of the various OLCF subsystems, and have developed a suite of pre-processing tools to make the raw data consumable. The cleansed logs are then ingested and federated into a central, scalable data warehouse, Splunk, that offers storage, indexing, querying, and visualization capabilities. We have further developed and deployed a set of tools to analyze these multiple disparate log streams in concert and derive operational insights. We describe our experience from developing and deploying the GUIDE infrastructure, and deriving valuable insights on the various subsystems, based on two years of operations in the production OLCF environment.</p>
          </div>
          
          
          <div id="/publication/dblp-confsc-vazhkudai-mtzwog-17/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-confsc-vazhkudai-mtzwog-17/-cite" class="tex hljs" data-filename="/publication/dblp-confsc-vazhkudai-mtzwog-17/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [MASCOTS 2017]
          
        </span>
        <a href="https://doi.org/10.1109/MASCOTS.2017.35" class="article-title" 
          style="color:inherit; font-weight: normal;">Toward Managing HPC Burst Buffers Effectively: Draining Strategy to Regulate Bursty I/O Behavior</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-confmascots-tang-hhlvt-17\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1109/MASCOTS.2017.35" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-confmascots-tang-hhlvt-17\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-confmascots-tang-hhlvt-17/-abstract" style="display: none;">
            <p class="abstract abstract-text">HPC (high-performance computing) applications usually show bursty I/O behaviors. In order to expedite the applications, permanent storage systems are usually provisioned to serve such I/O bursts. Approaching the era of exascale computing, non-volatile RAM is introduced as burst buffers, to absorb the bursty bulk data and relax the I/O provisioning requirement of the permanent storage systems. However, without judiciously draining the burst buffers, I/O bursts are passed down to the underlying storage systems, which causes severe I/O contention issues.In order to minimize the I/O provisioning requirement and resolve the issues caused by I/O bursts, we propose a proactive draining scheme to manage the draining process of distributed node-local burst buffers. In addition, we develop an I/O provisioning model to predict the minimized I/O provisioning requirement for permanent storage systems. Evaluation results show that applying the proactive draining scheme largely relaxes the I/O provisioning requirement while preserving the I/O performance of underlying storage systems.</p>
          </div>
          
          
          <div id="/publication/dblp-confmascots-tang-hhlvt-17/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-confmascots-tang-hhlvt-17/-cite" class="tex hljs" data-filename="/publication/dblp-confmascots-tang-hhlvt-17/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [HPCA 2016]
          
        </span>
        <a href="https://doi.org/10.1109/HPCA.2016.7446091" class="article-title" 
          style="color:inherit; font-weight: normal;">A large-scale study of soft-errors on GPUs in the field</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-confhpca-nie-tgsr-16\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1109/HPCA.2016.7446091" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-confhpca-nie-tgsr-16\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-confhpca-nie-tgsr-16/-abstract" style="display: none;">
            <p class="abstract abstract-text">Parallelism provided by the GPU architecture has enabled domain scientists to simulate physical phenomena at a much faster rate and finer granularity than what was previously possible by CPU-based large-scale clusters. Architecture researchers have been investigating reliability characteristics of GPUs and innovating techniques to increase the reliability of these emerging computing devices. Such efforts are often guided by technology projections and simplistic scientific kernels, and performed using architectural simulators and modeling tools. Lack of large-scale field data impedes the effectiveness of such efforts. This study attempts to bridge this gap by presenting a large-scale field data analysis of GPU reliability. We characterize and quantify different kinds of soft-errors on the Titan supercomputer's GPU nodes. Our study uncovers several interesting and previously unknown insights about the characteristics and impact of soft-errors.</p>
          </div>
          
          
          <div id="/publication/dblp-confhpca-nie-tgsr-16/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-confhpca-nie-tgsr-16/-cite" class="tex hljs" data-filename="/publication/dblp-confhpca-nie-tgsr-16/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [SC 2016]
          
        </span>
        <a href="https://doi.org/10.1109/SC.2016.19" class="article-title" 
          style="color:inherit; font-weight: normal;">Compiler-directed lightweight checkpointing for fine-grained guaranteed soft error recovery</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-confsc-liu-jlt-16\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1109/SC.2016.19" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-confsc-liu-jlt-16\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-confsc-liu-jlt-16/-abstract" style="display: none;">
            <p class="abstract abstract-text">This paper presents Bolt, a compiler-directed soft error recovery scheme, that provides fine-grained and guaranteed recovery without excessive performance and hardware overhead. To get rid of expensive hardware support, the compiler protects the architectural inputs during their entire liveness period by safely checkpointing the last updated value in idempotent regions. To minimize the performance overhead, Bolt leverages a novel compiler analysis that eliminates those checkpoints whose value can be reconstructed by other checkpointed values without compromising the recovery guarantee. As a result, Bolt incurs only 4.7% performance overhead on average which is 57% reduction compared to the state-of-the-art scheme that requires expensive hardware support for the same recovery guarantee as Bolt.</p>
          </div>
          
          
          <div id="/publication/dblp-confsc-liu-jlt-16/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-confsc-liu-jlt-16/-cite" class="tex hljs" data-filename="/publication/dblp-confsc-liu-jlt-16/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [SC 2016]
          
        </span>
        <a href="https://doi.org/10.1109/SC.2016.41" class="article-title" 
          style="color:inherit; font-weight: normal;">Granularity and the cost of error recovery in resilient AMR scientific applications</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-confsc-dubey-fgct-16\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1109/SC.2016.41" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-confsc-dubey-fgct-16\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-confsc-dubey-fgct-16/-abstract" style="display: none;">
            <p class="abstract abstract-text">Supercomputing platforms are expected to have larger failure rates in the future because of scaling and power concerns. The memory and performance impact may vary with error types and failure modes. Therefore, localized recovery schemes will be important for scientific computations, including failure modes where application intervention is suitable for recovery. We present a resiliency methodology for applications using structured adaptive mesh refinement, where failure modes map to granularities within the application for detection and correction. This approach also enables parameterization of cost for differentiated recovery. The cost model is built with tuning parameters that can be used to customize the strategy for different failure rates in different computing environments. We also show that this approach can make recovery cost proportional to the failure rate.</p>
          </div>
          
          
          <div id="/publication/dblp-confsc-dubey-fgct-16/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-confsc-dubey-fgct-16/-cite" class="tex hljs" data-filename="/publication/dblp-confsc-dubey-fgct-16/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [MICRO 2016]
          
        </span>
        <a href="https://doi.org/10.1109/MICRO.2016.7783728" class="article-title" 
          style="color:inherit; font-weight: normal;">Low-cost soft error resilience with unified data verification and fine-grained recovery for acoustic sensor based detection</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-confmicro-liu-jlt-16\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1109/MICRO.2016.7783728" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-confmicro-liu-jlt-16\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-confmicro-liu-jlt-16/-abstract" style="display: none;">
            <p class="abstract abstract-text">This paper presents Turnstile, a hardware/software cooperative technique for low-cost soft error resilience. Leveraging the recent advance of acoustic sensor based soft error detection, Turnstile achieves guaranteed recovery by taking into account the bounded detection latency. The compiler forms verifiable regions and selectively inserts store instructions to checkpoint their register inputs so that Turnstile can verify the register/memory states with regard to a region boundary in a unified way without expensive register file protection. At runtime, for each region, Turnstile regards any stores (to both memory and register checkpoints) as unverified, and thus holds them in a store queue until the region ends and spends the time of the error detection latency. If no error is detected during the time, the verified stores are merged into memory systems, and registers are checkpointed. When all the stores including checkpointing stores prior to a region boundary are verified, the architectural and memory states with regard to the boundary are verified, thus it can serve as a recovery point. In this way, Turnstile contains the errors within the core without extra memory buffering. When an error is detected, Turnstile invalidates unverified entries in the store queue and restores the checkpointed register values to get the architectural and memory states back to what they were at the most recently verified region boundary. Then, Turnstile simply redirects program control to the verified region boundary and continues execution. The experimental results demonstrate that Turnstile can offer guaranteed soft error recovery with low performance overhead (<;8% on average).   </p>
          </div>
          
          
          <div id="/publication/dblp-confmicro-liu-jlt-16/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-confmicro-liu-jlt-16/-cite" class="tex hljs" data-filename="/publication/dblp-confmicro-liu-jlt-16/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [DSN 2016]
          
        </span>
        <a href="https://doi.org/10.1109/DSN.2016.36" class="article-title" 
          style="color:inherit; font-weight: normal;">Power-Capping Aware Checkpointing: On the Interplay Among Power-Capping, Temperature, Reliability, Performance, and Energy</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-confdsn-tang-tghleh-16\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1109/DSN.2016.36" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-confdsn-tang-tghleh-16\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-confdsn-tang-tghleh-16/-abstract" style="display: none;">
            <p class="abstract abstract-text">Checkpoint and restart mechanisms have been widely used in large scientific simulation applications to make forward progress in case of failures. However, none of the prior works have considered the interaction of power-constraint with temperature, reliability, performance, and checkpointing interval. It is not clear how power-capping may affect optimal checkpointing interval. What are the involved reliability, performance, and energy trade-offs? In this paper, we develop a deep understanding about the interaction between power-capping and scientific applications using checkpoint/restart as resilience mechanism, and propose a new model for the optimal checkpointing interval (OCI) under power-capping. Our study reveals several interesting, and previously unknown, insights about how power-capping affects the reliability, energy consumption, performance.</p>
          </div>
          
          
          <div id="/publication/dblp-confdsn-tang-tghleh-16/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-confdsn-tang-tghleh-16/-cite" class="tex hljs" data-filename="/publication/dblp-confdsn-tang-tghleh-16/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    
    














<div class="view-list-item">
  <div class="container">
    <div class="row">
      <div class="col">
        <span style="
        color:maroon;
        font-weight: bold;">
          
          
            
            [IPDPS 2016]
          
        </span>
        <a href="https://doi.org/10.1109/IPDPS.2016.100" class="article-title" 
          style="color:inherit; font-weight: normal;">Reducing Waste in Extreme Scale Systems through Introspective Analysis</a>
        

        

        

        
        <div class="btn-links">
          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_visibility('\/publication\/dblp-confipps-bautista-gomez-g-16\/')">
            Abstract
          </span>

          <a class="btn btn-outline-primary my-1 mr-1 btn-md" href="https://doi.org/10.1109/IPDPS.2016.100" target="_blank" rel="noopener">
            Paper
          </a>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Presentation
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md">
            Open-Source Artifact
          </span>

          <span class="btn btn-outline-primary my-1 mr-1 btn-md" onclick="toggle_cite('\/publication\/dblp-confipps-bautista-gomez-g-16\/')">
            BibTex
          </span>

        </div>
        
        <div>
          <div id="/publication/dblp-confipps-bautista-gomez-g-16/-abstract" style="display: none;">
            <p class="abstract abstract-text">Resilience is an important challenge for extreme-scale supercomputers. Today, failures in supercomputers are assumed to be uniformly distributed in time. However, recent studies show that failures in high-performance computing systems are partially correlated in time, generating periods of higher failure density. Our study of the failure logs of multiple supercomputers show that periods of higher failure density occur with up to three times more than the average. We design a monitoring system that listens to hardware events and forwards important events to the runtime to detect those regime changes. We implement a runtime capable of receiving notifications and adapt dynamically. In addition, we build an analytical model to predict the gains that such dynamic approach could achieve. We demonstrate that in some systems, our approach can reduce the wasted time by over 30%.</p>
          </div>
          
          
          <div id="/publication/dblp-confipps-bautista-gomez-g-16/-cite-div" style="display: none;">
            <pre>
              <code id="/publication/dblp-confipps-bautista-gomez-g-16/-cite" class="tex hljs" data-filename="/publication/dblp-confipps-bautista-gomez-g-16/cite.bib"></code>
            </pre>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</div>
    
    

    <div class="container see-all">
      <a href="/publication/">
        See all publications
        <i class="fas fa-angle-right"></i>
      </a>
    </div>

  </div>
</div>

<script>
  function toggle_visibility(id) {
    let e = document.getElementById(id + "-abstract");
    let citeDiv = document.getElementById(id + "-cite-div");
    let $grid_pubs = $('#container-publications');
    if (e.style.display == 'block') {
      e.style.display = 'none';
      $grid_pubs.isotope('layout')
    }
    else {
      e.style.display = 'block';
      citeDiv.style.display = 'none';
      $grid_pubs.isotope('layout')
    }
  }

  function toggle_cite(id) {
    let $grid_pubs = $('#container-publications');
    let abstractDiv = document.getElementById(id + "-abstract");
    let citeDiv = document.getElementById(id + "-cite-div");
    let citeTarget = document.getElementById(id + "-cite");
    let $citeTarget = $(citeTarget);
    let filename = $citeTarget.attr('data-filename');
    if (citeDiv.style.display == 'block') {
      citeDiv.style.display = 'none';
      $grid_pubs.isotope('layout')
    }
    else {
      citeDiv.style.display = 'block';
      abstractDiv.style.display = 'none';
      $citeTarget.load(filename, function (resolve, reject) {
        $grid_pubs.isotope('layout')
      })
    }
  }
</script>

<style>
  .home-section:first-of-type {
    padding-top:0px;
    margin-top: 0px;
  }
  .wg-recent-pubs>.container {
    margin-left: 0;
    padding-left: 0;
    margin-top: -21px ;
    overflow-x: hidden;
    max-width: 100%;
  }

  .header {
    padding-left: 10%;
    padding-bottom: 20px;
    padding-top: 20px;
    margin-top: 0;
    margin-bottom: 30px;
    margin-right: 0;
    background-color:maroon;
    width:150%
  }
  .header>h1 {
      color:white
  }


  .abstract {
    font-size: 16px;
  }

  .fa-angle-right {
    padding-left: 5px;
  }

  .fa-angle-down {
    padding-left: 5px;
  }
</style>
    </div>
  </section>



      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks",
        'slides' : "Slides"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.66c553246b0f279a03be6e5597f72b52.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
